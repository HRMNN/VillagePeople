{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Where did the Village People go?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "- <a href='#DataMining'>Data Mining</a><br>\n",
    "- <a href='#DataCleaning'>Data Cleaning</a><br>\n",
    "- <a href='#DataAnalysis'>Data Analysis</a><br>\n",
    "- <a href='#Prediction'>Prediction</a><br>\n",
    "- <a href='#Clustering'>Clustering</a><br>\n",
    "- <a href='#Conclusion'>Conclusion</a><br>\n",
    "- <a href='#FutureWorks'>Future Works</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up General Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames\n",
    "import pandas as pd\n",
    "# Basic Plotting for Exploratory Data Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "# Fancy Plotting\n",
    "import seaborn as sns\n",
    "# Array and Array-Math\n",
    "import numpy as np\n",
    "# Geospatial Visualization\n",
    "import geopandas as gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Homebrew Functions\n",
    "- These Functions are tailored to the Dataset provided by the Bertelsmann Foundation<br>\n",
    "- The first features of the Dataset are not timeseries. After that, only timeseries of the same length follow.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function extracts all the features from a given year out of all timesries.\n",
    "def get_year(year):\n",
    "    return(FEATURE_TITLES[range(NON_TIMESERIES+year-MIN_YEAR,\n",
    "                                data_demo_cln.shape[1],\n",
    "                                MAX_YEAR - MIN_YEAR + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Time Series of a certain Feature (feature titles)\n",
    "def get_feature(feature):\n",
    "    # Where the Features Time Series starts\n",
    "    start = NON_TIMESERIES+feature*(MAX_YEAR - MIN_YEAR + 1)\n",
    "    # Return the Columns of Timeseries\n",
    "    return data_demo_cln.columns[range(start,\n",
    "                              start+(MAX_YEAR - MIN_YEAR + 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homebrew Functions for Data Mining / Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Missing Data in a Time Series using the existing Data before and after the gap\n",
    "def fillr3(data):\n",
    "    # Return Timeseries if gapless\n",
    "    if(data.isna().sum() == len(data)):\n",
    "        return(data)    \n",
    "\n",
    "    # Find the first existing value\n",
    "    counter = 0\n",
    "    first_value = 0\n",
    "    while counter < len(data):\n",
    "        section = data[:counter]\n",
    "        if section.isna().sum() == len(section):\n",
    "            result = counter\n",
    "        counter +=1\n",
    "    first_value = result\n",
    "\n",
    "    # Find the last existing Value\n",
    "    data = data[::-1]\n",
    "    counter = 0\n",
    "    last_value = 0\n",
    "    while counter < len(data):\n",
    "        section = data[:counter]\n",
    "        if section.isna().sum() == len(section):\n",
    "            result = counter\n",
    "        counter +=1\n",
    "    last_value = len(data) - result -1\n",
    "    data = data[::-1]\n",
    "\n",
    "    ## Fill the Missing Data with\n",
    "    # the first existing Datapoint, since the Gap is in beginning\n",
    "    beg = data.bfill()[:first_value]\n",
    "    # the mean of the Datapoint before and after the Gap\n",
    "    mid = ((data.bfill()+data.ffill())/2)[first_value:last_value]\n",
    "    # the last existing Datapoint, since the Gap is in beginning    \n",
    "    end = data.ffill()[last_value:]\n",
    "\n",
    "    return(beg.append(mid.append(end)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function Takes the name of a Dataset from Open Data Soft, downloads the GeoJson and turns it into a Geopanda.\n",
    "def geo_from_ods(title):\n",
    "    path  = \"https://public.opendatasoft.com/explore/dataset/\"+title+\"/download/?format=geojson\"\n",
    "    geods = gp.read_file(filename = path)\n",
    "    return geods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DataMining'></a>\n",
    "### Data Mining\n",
    "|Input|Tools & Techniques|Output|\n",
    "|-|-|-|\n",
    "|External Data|Import Data|Raw Data|\n",
    "|||Sources Table|\n",
    "|||Data Dictionary|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Geological Data for different Administrative Levels\n",
    "geo_nat_raw = geo_from_ods(\"european-union-countries\")\n",
    "geo_sta_raw = geo_from_ods(\"bundesland\")\n",
    "geo_dis_raw = geo_from_ods(\"landkreise-in-germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Demographic Data given by Bertelsmann Stiftung fom Excel File\n",
    "data_demo_raw = pd.read_excel(\"bertelsmann.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants derived from properties of Data Set\n",
    "NON_TIMESERIES = 3\n",
    "MIN_YEAR       = 2006\n",
    "MAX_YEAR       = 2017\n",
    "TIME_SPAN      = MAX_YEAR - MIN_YEAR + 1\n",
    "FEATURE_TITLES = data_demo_raw.columns\n",
    "N_TIMESERIES   = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handing over Data for Cleaning\n",
    "data_demo_cln = data_demo_raw.copy()\n",
    "geo_nat_cln   = geo_nat_raw.copy()\n",
    "geo_sta_cln   = geo_sta_raw.copy()\n",
    "geo_dis_cln   = geo_dis_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DataCleaning'></a>\n",
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Input|Tools & Techniques|Output|\n",
    "|-|-|-|\n",
    "|Raw Data|Reworking Features|Clean and Merged Data|\n",
    "|Data  Dictionary|Data Type Adaption|Data Dictionary Updates|\n",
    "||Handle Missing Data||\n",
    "||Merge Datasets||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reworking Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename Features\n",
    "# Choosen Names for Non-Timeseries-Features\n",
    "id_names   = [\"name\", \"gkz\", \"demtype\"]\n",
    "# Choosen Names for Timeseries\n",
    "timeseries = [\"pop\",\n",
    "              \"nodegree\",\n",
    "              \"alevel\",\n",
    "              \"immi\",\n",
    "              \"emmi\",\n",
    "              \"ei_balance\",\n",
    "              \"fam_balance\",\n",
    "              \"edu_balance\",\n",
    "              \"sec_balance\",\n",
    "              \"ger_balance\",\n",
    "              \"com_in_per_svb\",\n",
    "              \"com_out_per_svb\",\n",
    "              \"com_blc_per_pop\",\n",
    "              \"com_in_per_pop\",\n",
    "              \"com_out_per_pop\",\n",
    "              \"com_in_svb_fem\",\n",
    "              \"com_in_svb_men\",\n",
    "              \"com_out_svb_fem\",\n",
    "              \"com_out_svb_men\",\n",
    "              \"com_blc_pop_fem\",\n",
    "              \"com_blc_pop_men\"]\n",
    "# Generate new Feature Names by adding Years\n",
    "new_columns = id_names\n",
    "for ts in timeseries:\n",
    "    for idx in range(MIN_YEAR, MAX_YEAR + 1):\n",
    "        new_columns.append(ts+\"_\"+str(idx))\n",
    "# Rename Features        \n",
    "data_demo_cln.columns = new_columns\n",
    "\n",
    "# Adapt Constants\n",
    "FEATURE_TITLES = data_demo_cln.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Derive New Features from Existing Ones\n",
    "# Extract State Number from GKZ\n",
    "state = np.floor(data_demo_cln.gkz/1000000).astype(int)\n",
    "# Extract District Number from GKZ\n",
    "district = np.floor((data_demo_cln.gkz - state*1000000)/1000).astype(int)\n",
    "# Extract Municipality Number from GKZ\n",
    "municipality = (data_demo_cln.gkz - state*1000000 - district*1000).astype(int)\n",
    "# Insert New Information\n",
    "data_demo_cln.insert(3,\"municipality\",municipality)\n",
    "data_demo_cln.insert(3,\"district\",district)\n",
    "data_demo_cln.insert(3,\"state\",state)\n",
    "\n",
    "# Adapt Constants\n",
    "NON_TIMESERIES += 3\n",
    "FEATURE_TITLES = data_demo_cln.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Features ...\n",
    "# Administrative Level\n",
    "level = np.full_like(np.arange(data_demo_cln.shape[0], dtype=int), np.nan, dtype=np.double)\n",
    "level = pd.DataFrame(level)\n",
    "level.columns = [\"level\"]\n",
    "data_demo_cln.insert(0,\"level\",level)\n",
    "## .. and fill it\n",
    "# National Level\n",
    "deu_index = data_demo_cln[data_demo_cln.name == \"Deutschland\"].index\n",
    "data_demo_cln.iloc[deu_index,0]      = 0\n",
    "# States\n",
    "sta_index = data_demo_cln[(data_demo_cln.level != 0)&(data_demo_cln.district == 0)].index\n",
    "data_demo_cln.loc[sta_index,\"level\"] = 1\n",
    "# Districts\n",
    "dis_index = data_demo_cln[(data_demo_cln.level.isna())&(data_demo_cln.municipality == 0)].index\n",
    "data_demo_cln.loc[dis_index,\"level\"] = 2\n",
    "# Municipalities\n",
    "mun_index = data_demo_cln.level.isna()\n",
    "data_demo_cln.loc[mun_index,\"level\"] = 3\n",
    "\n",
    "# Adapt Constants\n",
    "NON_TIMESERIES += 1\n",
    "FEATURE_TITLES = data_demo_cln.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Geospatial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> In 2016 the districts of \"Göttingen\" and \"Osterode am Harz\" merged into one District named \"Göttingen\". The Geospatial Data needs to reflect that.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Göttingen \n",
    "indx_goe = geo_dis_cln[geo_dis_cln.name_2 == \"Göttingen\"].index[0]\n",
    "# Find Osterode am Harz\n",
    "indx_oah = geo_dis_cln[geo_dis_cln.name_2 == \"Osterode am Harz\"].index[0]\n",
    "# Göttingen and Oseterode am Harz the new District Code\n",
    "geo_dis_cln.loc[indx_goe,\"cca_2\"] = '03159'\n",
    "geo_dis_cln.loc[indx_oah,\"cca_2\"] = '03159'\n",
    "# Merge Shapes by Code\n",
    "geo_dis_cln = geo_dis_cln.dissolve(by='cca_2')\n",
    "geo_dis_cln = geo_dis_cln.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reduce to relevant features, rename and alter them to prepare for merging\n",
    "# National Level\n",
    "geo_nat_cln = geo_nat_cln.loc[:,[\"name_long\",\"geometry\"]]\n",
    "geo_nat_cln.columns = [\"name\",\"geo\"]\n",
    "geo_nat_cln.loc[21,\"name\"] = \"Deutschland\"\n",
    "# States Level\n",
    "geo_sta_cln = geo_sta_cln.loc[:,[\"gen\",\"geometry\"]]\n",
    "geo_sta_cln.columns = [\"name\",\"geo\"]\n",
    "# District Level\n",
    "geo_dis_cln = geo_dis_cln.loc[:,[\"cca_2\", \"geometry\"]]\n",
    "geo_dis_cln.columns = [\"code\",\"geo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform Format\n",
    "idx_numbers = data_demo_cln.columns[NON_TIMESERIES : data_demo_cln.shape[1]]\n",
    "for idx in idx_numbers:\n",
    "    temp_result = []\n",
    "    for obs in data_demo_cln[idx]:\n",
    "        if obs == 'k.A.':\n",
    "            temp_result.append(float('nan'))\n",
    "        else:\n",
    "            # Delete delimiter\n",
    "            result = obs.replace(\".\",\"\")\n",
    "            # Turn Comma into Dot\n",
    "            result = result.replace(\",\",\".\")\n",
    "            # Turn into float\n",
    "            temp_result.append(float(result))\n",
    "    data_demo_cln[idx] = temp_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demographic Data - Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step One: Use existing values to fill missing values\n",
    "# WARNING - TAKES A MINUTE OR TWO\n",
    "# Cycle through Timeseries\n",
    "for idx in range(N_TIMESERIES):\n",
    "    # Extract Feature-Titles for Timeseries\n",
    "    focus_on = get_feature(idx)\n",
    "    # Extract Obervation with at least one value and one missing value\n",
    "    look_at  = (data_demo_cln[focus_on].isna().sum(axis = 1) > 0)&(data_demo_cln[focus_on].isna().sum(axis = 1) < TIME_SPAN)    \n",
    "    # Handle Missing Values of selected Timeseries\n",
    "    data_demo_cln.loc[look_at,focus_on] = data_demo_cln.loc[look_at,focus_on].apply(fillr3, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step Two: Fill Completly empty Cases with mean - for each adminstrative level individually, skip Federal-Level\n",
    "# Cycle through Administrative Level\n",
    "for idx_lvl in range(1,4):\n",
    "    # Number of Observations with selected Administrative Level\n",
    "    n_obs   = data_demo_cln[data_demo_cln.level == idx_lvl].shape[0]\n",
    "    # Extract Features with at least one value and one missing value\n",
    "    fixable = data_demo_cln.columns[(data_demo_cln[data_demo_cln.level == idx_lvl].isna().sum() != 0)&(data_demo_cln[data_demo_cln.level == idx_lvl].isna().sum() != n_obs)]\n",
    "    # Cycle through those fixabel features    \n",
    "    for idx_ftr in fixable:\n",
    "        # Pick Observations from selected Administrative Level\n",
    "        look_at  = (data_demo_cln.level == idx_lvl)\n",
    "        # Select Feature\n",
    "        focus_on = idx_ftr\n",
    "        # Calculate Filling Value (= mean)\n",
    "        filler   = data_demo_cln.loc[look_at,focus_on].mean()\n",
    "        # Fill Missing Values     \n",
    "        data_demo_cln[idx_ftr].fillna(filler, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# National Level\n",
    "data_nat = geo_nat_cln.merge(data_demo_cln, on = \"name\", how = \"inner\")\n",
    "data_nat = gp.GeoDataFrame(data_nat, geometry = \"geo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Level\n",
    "data_sta = geo_sta_cln.merge(data_demo_cln, on = \"name\", how = \"inner\")\n",
    "data_sta = gp.GeoDataFrame(data_sta, geometry = \"geo\")\n",
    "# City States\n",
    "data_cit = data_sta[(data_sta.name == \"Hamburg\")|(data_sta.name == \"Berlin\")]\n",
    "data_cit = gp.GeoDataFrame(data_cit, geometry = \"geo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# District Level\n",
    "data_dis = data_demo_cln[data_demo_cln.level==2].copy()\n",
    "# Generate District Identifying Number, as used in the GeoData\n",
    "code = np.floor(data_dis.gkz/1000).astype(int).astype(str)\n",
    "for idx in code.index:\n",
    "    if len(code[idx]) == 4:\n",
    "        code[idx] = \"0\" + code[idx]\n",
    "    else:\n",
    "        pass\n",
    "code         = pd.DataFrame(code)\n",
    "code.columns = [\"code\"]\n",
    "# Add as new Feature\n",
    "data_dis     = data_dis.join(code, lsuffix='_caller', rsuffix='_other')\n",
    "# Execute actual merge\n",
    "data_dis = geo_dis_cln.merge(data_dis, on = \"code\", how = \"inner\")\n",
    "data_dis = gp.GeoDataFrame(data_dis, geometry = \"geo\")\n",
    "# Drop temporary Feature\n",
    "data_dis.drop(\"code\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing Municipalities geospatially is Future Works\n",
    "# Municipalities\n",
    "data_mun = data_demo_cln[data_demo_cln.level == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Switch to 3-degree Gauss-Kruger zone 3 Projection\n",
    "data_nat.crs = {'init':'epsg:4326'}\n",
    "data_nat     = data_nat.to_crs({'init':'epsg:31467'})\n",
    "data_sta.crs = {'init':'epsg:4326'}\n",
    "data_sta     = data_sta.to_crs({'init':'epsg:31467'})\n",
    "data_cit.crs = {'init':'epsg:4326'}\n",
    "data_cit     = data_cit.to_crs({'init':'epsg:31467'})\n",
    "data_dis.crs = {'init':'epsg:4326'}\n",
    "data_dis     = data_dis.to_crs({'init':'epsg:31467'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DataAnalysis'></a>\n",
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Input|Tools & Techniques|Output|\n",
    "|-|-|-|\n",
    "|Clean and Merged Data|Visualization|Data Understanding|\n",
    "|||Subject Matter Understanding|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of District/ Municipality Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select the Data to show\n",
    "feat = 0\n",
    "year = 2017\n",
    "\n",
    "# Get the Data\n",
    "show_me = data_dis[get_year(year)[feat]]\n",
    "\n",
    "# Turn the Data into a Plot\n",
    "sns.distplot(show_me)\n",
    "plt.title(\"Size of Districts\")\n",
    "plt.xlabel(\"Population\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.yticks([])\n",
    "\n",
    "# Save and Show the plot\n",
    "plt.savefig(\"./images/SizeOfDistricts.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/SizeOfDistricts.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Seen here is the distribution of distict population in 2017. The mean is almost 200k, while districts with more than 700k inhabitants are rare.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Data to show\n",
    "feat = \"pop_2017\"\n",
    "year = 2017\n",
    "\n",
    "# Get the Data\n",
    "dis_minmax = data_dis.nlargest(5, feat)[[\"name\", feat]]\n",
    "dis_minmax = dis_minmax.append(data_dis.nsmallest(5, feat)[[\"name\", feat]])\n",
    "dis_minmax.sort_values(by=[feat], inplace = True, ascending = False)\n",
    "\n",
    "# Turn the Data into a Plot\n",
    "sns.barplot(x  = feat, y = \"name\", data = dis_minmax,  palette=\"GnBu\")\n",
    "plt.title(\"The Largest and the Smallest Districts\")\n",
    "plt.xlabel(\"Population\")\n",
    "plt.xticks(rotation = 30)\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "# Save and Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/TopFlopDistricts.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/TopFlopDistricts.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Here you see the biggest, and smallest districts in Germany as of 2017. The population is put on a logarithmic scale. The actual values are shown below.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Data to show\n",
    "feat = 0\n",
    "year = 2017\n",
    "\n",
    "# Get the Data\n",
    "show_me = data_mun[get_year(year)[feat]]\n",
    "show_me = show_me[show_me<=100000]\n",
    "\n",
    "# Turn the Data into a Plot\n",
    "sns.distplot(show_me)\n",
    "plt.title(\"Size of Municipalities\")\n",
    "plt.xlabel(\"Population\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.yticks([])\n",
    "\n",
    "\n",
    "# Save and Show the plot\n",
    "plt.savefig(\"./images/SizeOfMunici.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/SizeOfMunici.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> The Dataset cuts off at 5k inhabitants on the Municipality level. Therefore calculating a mean/ minimum is not representative.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Data to show\n",
    "feat = \"pop_2017\"\n",
    "year = 2017\n",
    "\n",
    "# Get the Data\n",
    "mun_minmax = data_mun.nlargest(10, feat)[[\"name\",feat]]\n",
    "\n",
    "# Turn the Data into a Plot\n",
    "sns.barplot(x  = feat, y = \"name\", data = mun_minmax,  palette=\"GnBu\")\n",
    "plt.title(\"The Largest Municipalites\")\n",
    "plt.xlabel(\"Population\")\n",
    "plt.xticks(rotation = 30)\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "# Save and Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/TopMunici.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/TopMunici.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> However, creating a list of the Top 10 yields useful information</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population Development 2006 - 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the Data\n",
    "show_me = (data_dis.pop_2017 - data_dis.pop_2006)/data_dis.pop_2006*100\n",
    "\n",
    "# Turn the Data into a Plot\n",
    "sns.distplot(show_me)\n",
    "plt.title(\"District Population Change 2006 - 2017\")\n",
    "plt.xlabel(\"Change in %\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.yticks([])\n",
    "\n",
    "# Save and Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/PopChangeDistrict.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/PopChangeDistrict.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Seen here the changes in Population</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_temp = data_dis.copy()\n",
    "data_temp[\"changes\"] = (data_dis.pop_2017 - data_dis.pop_2006)/data_dis.pop_2006*100\n",
    "\n",
    "# Get the Data\n",
    "dis_minmax = data_temp.nlargest(5, 'changes')[[\"name\",\"changes\"]]\n",
    "dis_minmax = dis_minmax.append(data_temp.nsmallest(5, 'changes')[[\"name\",\"changes\"]])\n",
    "dis_minmax.sort_values(by=[\"changes\"],inplace = True, ascending = False)\n",
    "\n",
    "# Turn the Data into a Plot\n",
    "sns.barplot(x = \"changes\", y = \"name\", data = dis_minmax, palette = \"GnBu\")\n",
    "plt.title(\"The Biggest Changes in Population, District\")\n",
    "plt.xlabel(\"Change in %\")\n",
    "plt.xticks(rotation = 30)\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "# Save and Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/TopFlopDistrictChanges.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/TopFlopDistrictChanges.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Here you can see the highest changes</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add City States\n",
    "data_cit[\"changes\"] = (data_cit.pop_2017 - data_cit.pop_2006)/data_cit.pop_2006*100\n",
    "data_temp = data_temp.append(data_cit,sort=False).reset_index(drop=True)\n",
    "data_cit.drop(\"changes\", axis = 1, inplace = True)\n",
    "\n",
    "# Choose Data to Plot\n",
    "feat = \"changes\"\n",
    "\n",
    "# Center Legend\n",
    "extrema = data_temp[feat].abs().max()\n",
    "\n",
    "# Plotting\n",
    "fig, (ax) = plt.subplots(1, 1)\n",
    "\n",
    "data_temp.plot(column = feat,\n",
    "              ax     = ax,\n",
    "              legend = True,\n",
    "              cmap   = 'RdYlGn',\n",
    "              vmax   = extrema,\n",
    "              vmin   = -extrema)\n",
    "plt.axis('off')\n",
    "plt.title(\"District Population Change 2006 - 2017\")\n",
    "plt.savefig(\"./images/changemap.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/changemap.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> The East is loosing its population, but only on in the rural areas. Urban centers nationwide are growing. So are the belts around Germanies Top 3 cities: Berlin, Hamburg and Munich - which are also growing. Cologne's surroundings are not profiting from its growing center.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the Data\n",
    "show_me = (data_mun.pop_2017 - data_mun.pop_2006)/data_mun.pop_2006*100\n",
    "\n",
    "# Turn the Data into a Plot\n",
    "sns.distplot(show_me)\n",
    "\n",
    "plt.title(\"Population Change 2006 - 2017, Municipality\")\n",
    "plt.xlabel(\"Change in %\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"Count\")\n",
    "plt.yticks([])\n",
    "\n",
    "# Save and Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/PopChangeMunici.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/PopChangeMunici.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Seen here are the percentual changes in those 11 years on the municipality level.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = data_mun.copy()\n",
    "data_temp[\"changes\"] = (data_mun.pop_2017 - data_mun.pop_2006)/data_mun.pop_2006*100\n",
    "\n",
    "# Get the Data\n",
    "mun_minmax = data_temp.nlargest(5, 'changes')[[\"name\",\"changes\"]]\n",
    "mun_minmax = mun_minmax.append(data_temp.nsmallest(5, 'changes')[[\"name\",\"changes\"]])\n",
    "mun_minmax.sort_values(by=[\"changes\"],inplace = True, ascending = False)\n",
    "\n",
    "# Turn the Data into a Plot\n",
    "sns.barplot(x = \"changes\", y = \"name\", data = mun_minmax, palette = \"GnBu\")\n",
    "plt.title(\"The Biggest Changes in Population, Municipality\")\n",
    "plt.xlabel(\"Change in %\")\n",
    "plt.xticks(rotation = 30)\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "# Save and Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/TopFlopMunicipalityChanges.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/TopFlopMunicipalityChanges.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> The biggest winners, and loosers, population wise. Note that Boostedt was one of the smalles municipalities in the first place an barely made the 5k limit.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner-German Migration by Agegroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_temp = data_dis.copy()\n",
    "data_temp = data_temp.append(data_cit,sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Data to Plot\n",
    "feat = \"fam_balance_2017\"\n",
    "\n",
    "# Center Legend\n",
    "extrema = data_temp[feat].abs().max()\n",
    "\n",
    "# Plotting\n",
    "fig, (ax) = plt.subplots(1, 1)\n",
    "\n",
    "data_temp.plot(column = feat,\n",
    "              ax     = ax,\n",
    "              legend = True,\n",
    "              cmap   = 'RdYlGn',\n",
    "              vmax   = extrema,\n",
    "              vmin   = -extrema)\n",
    "plt.axis('off')\n",
    "plt.title(\"Family Migration\")\n",
    "plt.savefig(\"./images/FamilyMigration.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/FamilyMigration.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Families leave the cities for the rural areas.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Choose Data to Plot\n",
    "feat = \"edu_balance_2017\"\n",
    "\n",
    "# Center Legend\n",
    "extrema = data_temp[feat].abs().max()\n",
    "\n",
    "# Plotting\n",
    "fig, (ax) = plt.subplots(1, 1)\n",
    "\n",
    "data_temp.plot(column = feat,\n",
    "              ax     = ax,\n",
    "              legend = True,\n",
    "              cmap   = 'RdYlGn',\n",
    "              vmax   = extrema,\n",
    "              vmin   = -extrema)\n",
    "plt.axis('off')\n",
    "plt.title(\"Educational Migration\")\n",
    "plt.savefig(\"./images/EducationalMigration.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/EducationalMigration.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> While people 18-24 leave the countryside and flock to the cities.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Data to Plot\n",
    "feat = \"sec_balance_2017\"\n",
    "\n",
    "# Center Legend\n",
    "extrema = data_temp[feat].abs().max()\n",
    "\n",
    "# Plotting\n",
    "fig, (ax) = plt.subplots(1, 1)\n",
    "\n",
    "data_temp.plot(column = feat,\n",
    "              ax     = ax,\n",
    "              legend = True,\n",
    "              cmap   = 'RdYlGn',\n",
    "              vmax   = extrema,\n",
    "              vmin   = -extrema)\n",
    "plt.axis('off')\n",
    "plt.title(\"Second Half of Life Migration\")\n",
    "plt.savefig(\"./images/SECMigration.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/SECMigration.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> And around 50 the Germans return.</i> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Data to Plot\n",
    "feat = \"ger_balance_2017\"\n",
    "\n",
    "# Center Legend\n",
    "extrema = data_temp[feat].abs().max()\n",
    "\n",
    "# Plotting\n",
    "fig, (ax) = plt.subplots(1, 1)\n",
    "\n",
    "data_temp.plot(column = feat,\n",
    "              ax     = ax,\n",
    "              legend = True,\n",
    "              cmap   = 'RdYlGn',\n",
    "              vmax   = extrema,\n",
    "              vmin   = -extrema)\n",
    "plt.axis('off')\n",
    "plt.title(\"Old Age Migration\")\n",
    "plt.savefig(\"./images/OldAgeMigration.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/OldAgeMigration.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> And when reaching the pension-age, people continue to leave the cities - however they also leave certain rural counties for others.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Features\n",
    "(a quick look into correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data_dis[get_year(2017)].corr().abs())\n",
    "plt.savefig(\"./images/CorrDis.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/CorrDis.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data_mun[get_year(2017)].corr().abs())\n",
    "plt.savefig(\"./images/CorrMun.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/CorrMun.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Input|Tools & Techniques|Output|\n",
    "|-|-|-|\n",
    "|Clean and Merged Data|Visualization|Data Understanding|\n",
    "||Regression Models|Subject Matter Understanding|\n",
    "||Clustering||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "# Evaluate Cluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "# KNN Regrssor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Model Evaluation via MAE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Measuring Time\n",
    "import time\n",
    "# Gradient Boosting Regressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Random Forrest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homebrew Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting/ Handling the Bertelsmann Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract certain Feature of a certain year (feature title)\n",
    "def get_dependent_variable(year):\n",
    "    return(get_feature(dependent_variable)[(year-MIN_YEAR)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all Features of a certain year-span (feature titles)\n",
    "def get_years(start_year,end_year):\n",
    "    # Set up Collector for resulst\n",
    "    result = []\n",
    "    #Cycle through years\n",
    "    while start_year <= end_year:\n",
    "        # Get Features of selected year, add it to collector\n",
    "        result.extend(get_year(start_year))  \n",
    "        # Prepare next iteration\n",
    "        start_year += 1\n",
    "    # Return Collector\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract independent Features' Data for certain Timespan\n",
    "def indep_data_from_years(start_year,end_year):\n",
    "    # Extract Features' Titles\n",
    "    independent_features_pred = get_years(start_year,end_year)\n",
    "    # Get (in)dependent Data\n",
    "    result = data[independent_features_pred]\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dependent Features' Data for certain point of time\n",
    "def dep_data_from_years(year):\n",
    "    # Get independent Feature Title            \n",
    "    dependent_feature = get_dependent_variable(year)        \n",
    "    # Get (in)dependent Data\n",
    "    result = data[dependent_feature]\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with my Prediction approach: I - Setting the Foundations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a DataFrame with the possible Combinations of \"Xt + Xtuse-1 = Yt+use-1+lif\"\n",
    "# for given \"use\"/\"lif\", used when creating the model\n",
    "def generate_ulc_year_combos_model(use, lif):\n",
    " \n",
    "    # Set up Collector for Results\n",
    "    result = []\n",
    "    # Starting Year of Data\n",
    "    counter = MIN_YEAR\n",
    "    # Cycle through possible Combinations\n",
    "    while counter + use + lif <= MAX_YEAR + 1:\n",
    "        # Add Results (starting year, ending year, prediction year) to Collector\n",
    "        result.append([(counter),(counter + use - 1),(counter + use + lif -1 )])\n",
    "        # Set up for potential next Iteration of Loop\n",
    "        counter += 1  \n",
    "    # Turn Results into DataFrame\n",
    "    result = pd.DataFrame(result)\n",
    "    # Name Collumns\n",
    "    result.columns = [\"start_year\",\"end_year\",\"predict_year\"]\n",
    "    # Return Dataframes with possible Combinations\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generates all the possible \"use\" / \"look into future\" combinatios, given the timespan of \n",
    "# the available data\n",
    "def generate_use_lif_combinations():\n",
    "\n",
    "    # Collector for Results\n",
    "    result = []\n",
    "    # The Minimum Ammount of Years to utilize as dependent data\n",
    "    use = 1\n",
    "    # The Minimum Ammount of Years to predict into the future to\n",
    "    lif = 1\n",
    "    # Cycle through all the combinations of \"use\"\n",
    "    while use + lif <= TIME_SPAN:\n",
    "        # Cycle through all the combinations of \"lif\"               \n",
    "        while use + lif <= TIME_SPAN:\n",
    "            # Store resulting combination in collector\n",
    "            result.append([use,lif])\n",
    "            # Prepare next iteration\n",
    "            lif += 1\n",
    "        # Prepare nex Iteration\n",
    "        lif  = 1\n",
    "        use += 1\n",
    "\n",
    "    # Turn result into DataFrame\n",
    "    result = pd.DataFrame(result)\n",
    "    # Name Columns\n",
    "    result.columns = [\"use\",\"lif\"]\n",
    "    # Return Result\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with my Prediction approach: II - Building the Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction with given model and timespan\n",
    "def make_pred(model, start_year, end_year):\n",
    "    # Get (in)dependent Data from Years for Predictions\n",
    "    X_pred = indep_data_from_years(start_year,end_year)   \n",
    "    # Make Predictions\n",
    "    y_pred = model.predict(X_pred)\n",
    "    # Return Values\n",
    "    return(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Collection of Models to choose the best from later\n",
    "def set_up_market(regressor, parameters, show_me):\n",
    "    start = time.time()\n",
    "    \n",
    "    # Loop Level 1: All Combinations of USE / LIF\n",
    "    ulc = generate_use_lif_combinations()   \n",
    "    # Set up Collectors for Results\n",
    "    results  = []       \n",
    "    for idx in ulc.index:\n",
    "        use = ulc.use[idx]\n",
    "        lif = ulc.lif[idx]\n",
    "        ulc_yc = generate_ulc_year_combos_model(use, lif)\n",
    "\n",
    "        \n",
    "        # If show_me is True, the Rhombus-Diagram of each LIF / USE Combination will be set up,\n",
    "        # to be filled and plotted later\n",
    "        if show_me:\n",
    "            canvas_small   = pd.DataFrame(np.full(((MAX_YEAR - MIN_YEAR),\n",
    "                                                   (2 * (MAX_YEAR - MIN_YEAR) - 1)),\n",
    "                                                  np.nan))\n",
    "            canvas_small.index   = range(MIN_YEAR + 1 ,MAX_YEAR + 1)\n",
    "            canvas_small.columns   = range(-10,11)\n",
    " \n",
    "\n",
    "        # Loop Level 2: All Combinations of Years (independent and dependent Data) to fit model\n",
    "        for idxidx in ulc_yc.index:\n",
    "            start_year_model   = ulc_yc.start_year[idxidx]\n",
    "            end_year_model     = ulc_yc.end_year[idxidx]\n",
    "            predict_year_model = ulc_yc.predict_year[idxidx]\n",
    "            # Get (in)dependent Feature Titles\n",
    "            independent_features_model  = get_years(start_year_model,\n",
    "                                                    end_year_model)\n",
    "            dependent_feature_model     = get_dependent_variable(predict_year_model)\n",
    "            # Get (in)dependent Data\n",
    "            X_model = data[independent_features_model]\n",
    "            y_model = data[dependent_feature_model]\n",
    "     \n",
    "            # Choose Model to set up\n",
    "            model = regressor(**parameters)       \n",
    "            model.fit(X_model, y_model)             \n",
    "\n",
    "                \n",
    "            # Loop Level 3: Try Model on all known Data for Scoring\n",
    "            for idxidxidx in ulc_yc.index:\n",
    "                # Extract Years for Prediction\n",
    "                start_year_pred   = ulc_yc.start_year[idxidxidx]\n",
    "                end_year_pred     = ulc_yc.end_year[idxidxidx]\n",
    "                predict_year_pred = ulc_yc.predict_year[idxidxidx]        \n",
    "                # Determine \"Push\": How many Years forward from fitting was the model used\n",
    "                push = predict_year_pred - predict_year_model           \n",
    "                \n",
    "                # Get y True\n",
    "                y_true = dep_data_from_years(predict_year_pred)\n",
    "                # Make Prediction with given model and timespan\n",
    "                y_pred = make_pred(model, start_year_pred, end_year_pred)\n",
    "\n",
    "                # Determine score\n",
    "                score = scoring(y_true, y_pred)\n",
    "            \n",
    "                # Collector for Results\n",
    "                results.append([use,lif,\n",
    "                                start_year_model, end_year_model, predict_year_model,\n",
    "                                push,\n",
    "                                start_year_pred, end_year_pred, predict_year_pred,\n",
    "                                score,\n",
    "                                model])                           \n",
    "      \n",
    "                # If show_me is True, the set-up Rhombus-Diagram of each LIF / USE Combination will be filled,\n",
    "                # to be plotted later\n",
    "                if show_me:\n",
    "                    canvas_small.loc[predict_year_model,push] = score\n",
    "\n",
    "\n",
    "        # If show_me is True, the set up and filled Rhombus-Diagram of each LIF / USE Combination is plotted  \n",
    "        if show_me:\n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.title(\"Using \"+str(use)+\" years to predict \"+str(lif)+\" years in the future\")\n",
    "            sns.heatmap(canvas_small, annot = False, linewidth=0.0, cbar = True, cmap=\"YlGnBu\")\n",
    "            plt.xlabel(\"Model pushed ahead\")\n",
    "            plt.ylabel(\"Original Prediction Year\")       \n",
    "            plt.show()\n",
    "\n",
    "    # Turn Results Collector into Panda           \n",
    "    results          = pd.DataFrame(results)\n",
    "    results.columns  = [\"use\",\"lif\",\n",
    "                        \"start_year_model\", \"end_year_model\", \"predict_year_model\",\"push\",\n",
    "                        \"start_year_pred\", \"end_year_pred\", \"predict_year_pred\",\n",
    "                       \"score\", \"model\"]\n",
    "    \n",
    "    # Take Time\n",
    "    passed = time.time() - start\n",
    "    \n",
    "    # Return Results\n",
    "    return(passed, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes the Market\n",
    "def prune_market(rfe, shape):\n",
    "    # The Shape determinses which tests are used to determine the value of the model\n",
    "    if shape == \"triangle\":\n",
    "        rfe = rfe[rfe.push>0]\n",
    "    else:\n",
    "        pass\n",
    "    return rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_selection(rfe,shape,show_me,cut_off,name):\n",
    "    start = time.time()\n",
    "\n",
    "    # Select the relevant tests to determine the value of each model\n",
    "    rfe = prune_market(rfe, shape)\n",
    "\n",
    "    # Calculate the Mean Score for each model\n",
    "    rfe_mean = rfe.groupby([\"use\",\"lif\",\"start_year_model\",\"end_year_model\",\"predict_year_model\"], as_index = False)[\"score\"].mean()\n",
    " \n",
    "    # Best score for each lif\n",
    "    rfe_sum_min = rfe_mean.groupby([\"lif\"], as_index = False)[\"score\"].min()\n",
    "\n",
    "    # Calculate the mean Score\n",
    "    mean_score = rfe_sum_min.score.mean()\n",
    "    \n",
    "    # If show_me = True, the Scores of the best Selection will be Plotted\n",
    "    if show_me:\n",
    "        plt.plot(rfe_sum_min.score)\n",
    "        plt.plot(np.full((12, 1), mean_score))        \n",
    "        plt.ylabel(\"scoring\")\n",
    "        plt.xlabel(\"Years predicted ahead\")\n",
    "        plt.xticks(range(0,11),range(1,12))\n",
    "        # To enable multiple Scores in  one Plot\n",
    "        if name != \"\":\n",
    "            plt.savefig(\"./images/\"+name)\n",
    "            plt.close()    \n",
    "        if cut_off:\n",
    "            plt.show()\n",
    "    \n",
    "    # Calculate the mean Score\n",
    "    \n",
    "    # Create List of Indexes, leading to the best scoring model for each lif\n",
    "    # Future Works: Make this more elegant\n",
    "    best_combo = []\n",
    "    for idx in rfe_sum_min.index:\n",
    "        #rfe_mean[rfe_sum_min.score[idx]==rfe_mean.score]\n",
    "        sym = int(rfe_mean[rfe_sum_min.score[idx]==rfe_mean.score].start_year_model.reset_index(drop=True)[0])\n",
    "        eym = int(rfe_mean[rfe_sum_min.score[idx]==rfe_mean.score].end_year_model.reset_index(drop=True)[0])\n",
    "        pym = int(rfe_mean[rfe_sum_min.score[idx]==rfe_mean.score].predict_year_model.reset_index(drop=True)[0])\n",
    "        best_id = rfe[(rfe.start_year_model   == sym)&\n",
    "        (rfe.end_year_model     == eym)&\n",
    "        (rfe.predict_year_model == pym)].index[0]\n",
    "        best_combo.append(best_id)\n",
    "    \n",
    "    # Return Results\n",
    "    passed = time.time() - start    \n",
    "    return(passed,best_combo,mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up and Selecting Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings, chosen by User\n",
    "# Used DataSet\n",
    "data               = data_dis\n",
    "# Dependent Variable\n",
    "dependent_variable = 0\n",
    "# Scoring Method\n",
    "scoring            = mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Look into KNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regression Model\n",
    "regressor          = KNeighborsRegressor\n",
    "# Model Parameters\n",
    "parameters         = {\"n_neighbors\" : 2, \"algorithm\" : \"brute\"}\n",
    "# Set up Model Market\n",
    "time_passed_one, model_market = set_up_market(regressor, parameters, False)\n",
    "# Choose the Best Combination\n",
    "time_passed_two, best_combo, mean_score = best_selection(model_market,\"triangle\",True,True,\"KNregressor.png\")\n",
    "#print(\"Time passed:\", time_passed_one+time_passed_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/knregressor.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>KNN is fast (15s) and gives decent results. Graph shows performance for different lif. And mean.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying approach to Random Forrest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_to_build = 0\n",
    "counter = 2\n",
    "rfr_results = []\n",
    "while time_to_build < (2 * 60):\n",
    "    # Regression Model\n",
    "    regressor          = RandomForestRegressor\n",
    "    parameters         = {\"n_estimators\" : counter}\n",
    "    # Set up Model Market\n",
    "    time_passed_one, model_market = set_up_market(regressor, parameters, False)\n",
    "    # Choose the Best Combination\n",
    "    time_passed_two, best_combo, mean_score = best_selection(model_market,\"triangle\",False,False)\n",
    "    time_to_build = time_passed_one+time_passed_two\n",
    "    rfr_results.append([counter,time_to_build,mean_score])        \n",
    "    counter += 1\n",
    "rfr_results         = pd.DataFrame(rfr_results)\n",
    "rfr_results.columns = [\"n_estimators\",\"time\",\"mean_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot Results\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "fig.suptitle('Random Forest Regressor')\n",
    "\n",
    "# Plot Score per Number of Estimator\n",
    "ax1.plot(rfr_results.n_estimators,rfr_results.mean_score)\n",
    "ax1.set_ylabel(\"Average Score\")\n",
    "ax1.set_xlabel(\"Number of\", rotation = 45)\n",
    "\n",
    "# Plot Score per Time to fit Model\n",
    "ax2.scatter(x = rfr_results.time, y = rfr_results.mean_score, s = rfr_results.n_estimators)\n",
    "ax2.set_xticklabels(\"\")\n",
    "ax2.set_yticklabels(\"\")\n",
    "\n",
    "ax3.axis('off')\n",
    "\n",
    "# Plot Number of Estimators and the Time it takes to fit \n",
    "ax4.plot(rfr_results.time,rfr_results.n_estimators)\n",
    "ax4.set_xlabel(\"Time in Seconds\")\n",
    "ax4.set_ylabel(\"Estimators\", rotation = 45)\n",
    "\n",
    "# Handle Plot\n",
    "plt.figure(figsize=(50,50))\n",
    "fig.savefig(\"images/RFR.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/RFR.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>The Random Forest Regressor yields better results, but takes more time. The more trees involved, the better the performance / the longer it takes to set the model up. However, the results are still \"wobbly\" and the performance quickly plateaus.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Approach to Gradient Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_build = 0\n",
    "counter = 2\n",
    "gbr_results = []\n",
    "while time_to_build < (2 * 60):\n",
    "    # Regression Model\n",
    "    regressor          = GradientBoostingRegressor\n",
    "    parameters         = {\"n_estimators\" : counter}\n",
    "    # Set up Model Market\n",
    "    time_passed_one, model_market = set_up_market(regressor, parameters, False)\n",
    "    # Choose the Best Combination\n",
    "    time_passed_two, best_combo, mean_score = best_selection(model_market,\"triangle\",False,False)\n",
    "    time_to_build = time_passed_one+time_passed_two\n",
    "    gbr_results.append([counter,time_to_build,mean_score])        \n",
    "    counter += 1\n",
    "gbr_results         = pd.DataFrame(gbr_results)\n",
    "gbr_results.columns = [\"n_estimators\",\"time\",\"mean_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot Results\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "fig.suptitle('Gradient Boosting Regressor')\n",
    "\n",
    "# Plot Score per Number of Estimator\n",
    "ax1.plot(gbr_results.n_estimators,gbr_results.mean_score, color = \"orange\")\n",
    "ax1.set_ylabel(\"Average Score\")\n",
    "ax1.set_xlabel(\"Number of\", rotation = 45)\n",
    "\n",
    "# Plot Score per Time to fit Model\n",
    "ax2.scatter(x = gbr_results.time, y = gbr_results.mean_score, s = gbr_results.n_estimators, color = \"orange\")\n",
    "ax2.set_xticklabels(\"\")\n",
    "ax2.set_yticklabels(\"\")\n",
    "\n",
    "ax3.axis('off')\n",
    "\n",
    "# Plot Number of Estimators and the Time it takes to fit \n",
    "ax4.plot(gbr_results.time,gbr_results.n_estimators, color = \"orange\")\n",
    "ax4.set_xlabel(\"Time in Seconds\")\n",
    "ax4.set_ylabel(\"Estimators\", rotation = 45)\n",
    "\n",
    "# Handle Plot\n",
    "plt.figure(figsize=(50,50))\n",
    "fig.savefig(\"images/GBR.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/GBR.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> The Gradient Boost Regressor starts with a very bad score, but improves quickly.<br>\n",
    "To decide, a closer look needs to be made.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GBR\n",
    "sns.scatterplot(data = gbr_results[gbr_results.time>=60], x = \"time\", y = \"mean_score\",\n",
    "                color = \"orange\", size = \"n_estimators\", legend = False)\n",
    "# Plot RFR\n",
    "sns.scatterplot(data = rfr_results[rfr_results.time>=60], x = \"time\", y = \"mean_score\",\n",
    "                color = \"blue\", size = \"n_estimators\", legend = False)\n",
    "\n",
    "# Set Frame\n",
    "plt.title(\"Comparing Random Forrest with Gradient Boost\")\n",
    "plt.ylabel(\"Average Score\")\n",
    "plt.xlabel(\"Time in Seconds\")\n",
    "plt.savefig(\"images/RFRvsGBR.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/RFRvsGBR.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Around 80 seconds is the turning point. If more time is invested in setting up the model, Gradient Boost will outperform the Random Forrest. GBR also has not plateaued yet!</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Selected Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> After this step, there will be a collection of models to predict the Migration Balance and the Population on the Municipality and the District Level. For each there is an optimal model for each \"lif\" that needs to be chosen by the user.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no educational Data on the Municipalities. However, GDB does not handle missing values.\n",
    "# To keep things modular, the features will simply be turned tu \"0\".\n",
    "data_mun.loc[:,get_feature(1)] = 0\n",
    "data_mun.loc[:,get_feature(2)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings, chosen by User\n",
    "# Used DataSet\n",
    "data               = data_mun\n",
    "# Dependent Variable\n",
    "dependent_variable = 0\n",
    "# Scoring Method\n",
    "scoring            = mean_absolute_error\n",
    "# Regression Model\n",
    "regressor          = GradientBoostingRegressor\n",
    "parameter          = {\"n_estimators\" : 200}\n",
    "# Set up Model Market\n",
    "time_passed_one, mm_mun_pop = set_up_market(regressor, parameter, False)\n",
    "# Choose the Best Combination\n",
    "time_passed_two, bc_mun_pop, ms_mun_pop = best_selection(mm_mun_pop,\"triangle\",True,True,\"MUNpop.png\")\n",
    "print(\"Time passed:\", time_passed_one+time_passed_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/MUNpop.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>It took roughly 38 minutes to set up this model-series for predicting the migration balance on a municipality level. 200 estimators were used.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings, chosen by User\n",
    "# Used DataSet\n",
    "data               = data_mun\n",
    "# Dependent Variable\n",
    "dependent_variable = 5\n",
    "# Scoring Method\n",
    "scoring            = mean_absolute_error\n",
    "# Regression Model\n",
    "regressor          = GradientBoostingRegressor\n",
    "parameter          = {\"n_estimators\" : 200}\n",
    "# Set up Model Market\n",
    "time_passed_one, mm_mun_mibal = set_up_market(regressor, parameter, False)\n",
    "# Choose the Best Combination\n",
    "time_passed_two, bc_mun_mibal, ms_mun_mibal = best_selection(mm_mun_mibal,\"triangle\",True,True,\"MUNmibal.png\")\n",
    "print(\"Time passed:\", time_passed_one+time_passed_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/MUNmibal.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>It took roughly 38 minutes to set up this model-series for predicting the population on a municipality level. 200 estimators were used.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Settings, chosen by User\n",
    "# Used DataSet\n",
    "data               = data_dis\n",
    "# Dependent Variable\n",
    "dependent_variable = 0\n",
    "# Scoring Method\n",
    "scoring            = mean_absolute_error\n",
    "# Regression Model\n",
    "regressor          = GradientBoostingRegressor\n",
    "parameter          = {\"n_estimators\" : 2000}\n",
    "# Set up Model Market\n",
    "time_passed_one, mm_dis_pop = set_up_market(regressor,parameter, False)\n",
    "# Choose the Best Combination\n",
    "time_passed_two, bc_dis_pop, ms_dis_pop = best_selection(mm_dis_pop, \"triangle\",True,True,\"DISpop.png\")\n",
    "print(\"Time passed:\", time_passed_one+time_passed_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DISpop.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>It took roughly an hour to set up this model-series for predicting the population on a municipality level. 2000 estimators were used.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings, chosen by User\n",
    "# Used DataSet\n",
    "data               = data_dis\n",
    "# Dependent Variable\n",
    "dependent_variable = 5\n",
    "# Scoring Method\n",
    "scoring            = mean_absolute_error\n",
    "# Regression Model\n",
    "regressor          = GradientBoostingRegressor\n",
    "parameter          = {\"n_estimators\" : 1000}\n",
    "# Set up Model Market\n",
    "time_passed_one, mm_dis_mibal = set_up_market(regressor,parameter, False)\n",
    "# Choose the Best Combination\n",
    "time_passed_two, bc_dis_mibal, ms_dis_mibal = best_selection(mm_dis_mibal, \"triangle\",True,True,\"DISmibal.png\")\n",
    "print(\"Time passed:\", time_passed_one+time_passed_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DISmibal.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>It took roughly 29 minutes to set up this model-series for predicting the migration balance on a municipality level. 1000 estimators were used.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a DataFrame with the possible Combinations of \"Xt + Xtuse-1 = Yt+use-1+lif\"\n",
    "# for given \"use\"/\"lif\", used when making predictions\n",
    "def generate_ulc_year_combos_pred(use, lif):\n",
    "    # Set up Collector for Results\n",
    "    result = []\n",
    "    # Starting Year of Data\n",
    "    counter = MIN_YEAR + use - 1\n",
    "    # Cycle through possible Combinations\n",
    " \n",
    "    while counter  <= MAX_YEAR:\n",
    "        # Add Results (starting year, ending year, prediction year) to Collector\n",
    "        result.append([(counter - use + 1),(counter),(counter + lif)])\n",
    "        # Set up for potential next Iteration of Loop\n",
    "        counter += 1  \n",
    "\n",
    "    # Turn Results into DataFrame\n",
    "    result = pd.DataFrame(result)\n",
    "    # Name Columns\n",
    "    result.columns = [\"start_year\",\"end_year\",\"predict_year\"]\n",
    "    # Return Dataframes with possible Combinations \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Pedictions, with given mode (via best_combo/ model_market) and chosen range (lif)\n",
    "def predictionS(lif,best_combo,model_market):\n",
    "    # Extract Tools\n",
    "    model_idx = best_combo[lif-1]\n",
    "    use       = model_market.loc[model_idx,\"use\"]\n",
    "    model     = model_market.loc[model_idx,\"model\"]\n",
    "    \n",
    "    # Generate Combinations for Predictions\n",
    "    ulcycp    = generate_ulc_year_combos_pred(use, lif)\n",
    "    \n",
    "    # Set up Collector for Predictions\n",
    "    results = []\n",
    "    results = pd.DataFrame(results)\n",
    "    # Make Predictions\n",
    "    for idx in ulcycp.index:\n",
    "        # Extract Info for Predictions\n",
    "        start_year     = ulcycp.loc[idx,\"start_year\"]\n",
    "        end_year       = ulcycp.loc[idx,\"end_year\"]\n",
    "        predict_year   = ulcycp.loc[idx,\"predict_year\"]        \n",
    "        # Make Predictions\n",
    "        y_pred         = pd.DataFrame(make_pred(model, start_year, end_year))\n",
    "        results[[str(predict_year)]] = y_pred\n",
    "        \n",
    "    results.columns = range(int(results.columns[0]), int(results.columns[-1]) +1)\n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows one Example Prediction\n",
    "def show_example(data,feature,lif,best_combo,model_market,look_at,overlapse,filename,noshow):\n",
    "    plt.title(look_at+\", \"+timeseries_n[feature])\n",
    "    pred = predictionS(lif,best_combo,model_market)\n",
    "    look_at = data[data.name == look_at].index[0]\n",
    "    data.reset_index(inplace = True, drop = True)\n",
    "    past = data.loc[look_at,get_feature(feature)]\n",
    "    past.index = range(2006,2018)\n",
    "    if overlapse:\n",
    "        future = pred.loc[look_at,:]\n",
    "        plt.plot(past, color = \"blue\")\n",
    "        plt.plot(future, color = \"orange\")     \n",
    "    else:\n",
    "        future = pred.loc[look_at,2018:]  \n",
    "        future = past.append(future)\n",
    "        plt.plot(future, color = \"orange\")\n",
    "        plt.plot(past, color = \"blue\")\n",
    "    plt.xticks(range(2006,2017+lif+1),rotation=45)\n",
    "    plt.savefig(filename)\n",
    "    if noshow:\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_n = [\"Population\",\n",
    "              \"% no degree\",\n",
    "              \"% with a-Level\",\n",
    "              \"immigration per 1000\",\n",
    "              \"emmigration per 1000\",\n",
    "              \"migration balance per 1000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Municipalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Trials and visual exploration showed that looking into the future (lif) for certain numbers of years yields no plausible results. Here are graphs that show some more prominent Municipalities/ Districts.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_mun,5,10,bc_mun_mibal, mm_mun_mibal,\"Hannover\",False,\"./images/HanMigbal7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/HanMigbal7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Hannovers stream of Migration will become steady.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_mun,5,10,bc_mun_mibal, mm_mun_mibal,\"Plön (PLÖ)\", False,\"./images/PLOMigbal7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/PLOMigbal7.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_mun,5,10,bc_mun_mibal, mm_mun_mibal,\"Unterföhring\", False,\"./images/UNTMigbal7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/PLOMigbal7.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_example(data_mun,5,6,bc_mun_mibal, mm_mun_mibal,\"Eisenhüttenstadt\", False,\"./images/EISMigbal7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/EISMigbal7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Eissenhüttenstadt will recover.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_mun,0,6,bc_mun_pop, mm_dis_pop,\"Aachen\", False, \"./images/AacPop7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/AacPop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> The Municipality of Aachen will regain it's population that it lost during the 2011 census in one year.</i><br>\n",
    "<i> Hm. </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population in Districs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,5,7,bc_dis_mibal, mm_dis_mibal,\"Suhl\", False, \"./images/SUHmibal7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/SUHpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> The migration balance of Suhl will plateau around 1,5%.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,5,7,bc_dis_mibal, mm_dis_mibal,\"Zweibrücken\", False, \"./images/ZWEmibal7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/ZWEpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>So will Zweibrückens.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,5,7,bc_dis_mibal, mm_dis_mibal,\"Region Hannover\", False, \"./images/HANmibal7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/HANpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> The District \"Region of Hannover\" will continue to attract more and more people.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,5,7,bc_dis_mibal, mm_dis_mibal,\"Potsdam\", False, \"./images/POTmibal7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images/POTpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> The District of Potsdam will, within one year, drastically loose it's attracting forces. However, it will slowly recuperate.</i><br>\n",
    "<i>Hm.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,0,10,bc_dis_pop, mm_dis_pop,\"Potsdam\", False, \"./images/POTpop7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/POTpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> The fastest growing district 06-17 will continue to grow.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,0,10,bc_dis_pop, mm_dis_pop,\"München\", False, \"./images/MUNpop7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/MUNpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>However, Munich, the biggest District, population will have peaked in 2016 and continue its downfall.</i><br>\n",
    "<i>Hm.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,0,10,bc_dis_pop, mm_dis_pop,\"Region Hannover\", False, \"./images/HANpop7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/HANpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> The Region of Hannover - Germany's second biggest District - will remain steady until 2024 and then grow again.</i> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,0,10,bc_dis_pop, mm_dis_pop,\"Suhl\", False, \"./images/SUHpop7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/SUHpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Suhl, the second smallest district in Germany will continue to decline until 2023, but will recover within little time.</i><br>\n",
    "<i>Hm.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,0,10,bc_dis_pop, mm_dis_pop,\"Zweibrücken\", False, \"./images/ZWEpop7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/ZWEpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Zweibrücken, the smallest District, will have an interesting development. After stagnating, the population will jumpstart by gaining more then 10% in one year and continue to grow afterwards.</i><br>\n",
    "<i>Hm.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,0,10,bc_dis_pop, mm_dis_pop,\"Münster\", False, \"./images/MUEpop7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/MUEpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Münster, Germany's second fastes growing district, will continue to do so after a short slump.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,0,10,bc_dis_pop, mm_dis_pop,\"Spree-Neiße, LK\", False, \"./images/SNKpop7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/SNKpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Germany's second fastest shrinking district will continue to do so.</i> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(data_dis,0,10,bc_dis_pop, mm_dis_pop,\"Suhl\", False, \"./images/SHLpop7.png\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"./images/SHLpop7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Suhl, the fastest shrinking district however will see an population explosion in 2023.</i><br>\n",
    "<i>Hm.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif = 10\n",
    "plt.title(\"Germany's Population, excluding Berlin and Hamburg\")\n",
    "past = data_dis[get_feature(0)].sum()\n",
    "past.index = range(2006,2018)\n",
    "future = predictionS(10,bc_dis_pop,mm_dis_pop).sum()\n",
    "future = future.loc[2018:]  \n",
    "future = past.append(future)\n",
    "plt.plot(future, color = \"orange\")\n",
    "plt.plot(past, color = \"blue\")\n",
    "plt.xticks(range(2006,2017+lif+1),rotation=45)\n",
    "plt.savefig(\"./images/generalpop.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/generalpop.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Summing up all districts shows that the population in Germany (excluding Hamburg and Berlin) will rise, after slumping till 2021.</i><br>\n",
    "<i>Hm.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now  = data_dis[get_feature(0)][\"pop_2017\"]\n",
    "soon = predictionS(10,bc_dis_pop,mm_dis_pop).iloc[:,-1]\n",
    "\n",
    "data_temp = data_dis.copy()\n",
    "data_temp[\"changes\"] = (soon - now) / now * 100\n",
    "\n",
    "# Get the Data\n",
    "dis_minmax = data_temp.nlargest(5, 'changes')[[\"name\",\"changes\"]]\n",
    "dis_minmax = dis_minmax.append(data_temp.nsmallest(5, 'changes')[[\"name\",\"changes\"]])\n",
    "dis_minmax.sort_values(by=[\"changes\"],inplace = True, ascending = False)\n",
    "\n",
    "# Turn the Data into a Plot\n",
    "sns.barplot(x = \"changes\", y = \"name\", data = dis_minmax, palette = \"GnBu\")\n",
    "plt.title(\"The Biggest Changes in Population 2017-2027, District\")\n",
    "plt.xlabel(\"Change in %\")\n",
    "plt.xticks(rotation = 30)\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "# Save and Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/TopFlopDistrictPred.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/TopFlopDistrictPred.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Here you can see the fastest growing/ shrinking districts.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add City States\n",
    "data_cit[\"changes\"] = 0\n",
    "data_temp = data_temp.append(data_cit,sort=False).reset_index(drop=True)\n",
    "data_cit.drop(\"changes\", axis = 1, inplace = True)\n",
    "\n",
    "# Choose Data to Plot\n",
    "feat = \"changes\"\n",
    "\n",
    "# Center Legend\n",
    "extrema = data_temp[feat].abs().max()\n",
    "\n",
    "# Plotting\n",
    "fig, (ax) = plt.subplots(1, 1)\n",
    "\n",
    "data_temp.plot(column = feat,\n",
    "              ax     = ax,\n",
    "              legend = True,\n",
    "              cmap   = 'RdYlGn',\n",
    "              vmax   = extrema,\n",
    "              vmin   = -extrema)\n",
    "plt.axis('off')\n",
    "plt.title(\"District Population Change 2017 - 2027\")\n",
    "plt.savefig(\"./images/changemappred.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/changemappred.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> As it can be seen here, the east will either stabilize, or even grow - besides some exceptions.</i><br>\n",
    "<i>Hm.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now  = data_mun[get_feature(0)][\"pop_2017\"]\n",
    "soon = predictionS(10,bc_mun_pop,mm_mun_pop).iloc[:,-1]\n",
    "\n",
    "data_temp = data_mun.copy()\n",
    "data_temp[\"changes\"] = (soon - now) / now * 100\n",
    "\n",
    "# Get the Data\n",
    "mun_minmax = data_temp.nlargest(5, 'changes')[[\"name\",\"changes\"]]\n",
    "mun_minmax = mun_minmax.append(data_temp.nsmallest(5, 'changes')[[\"name\",\"changes\"]])\n",
    "mun_minmax.sort_values(by=[\"changes\"],inplace = True, ascending = False)\n",
    "\n",
    "# Turn the Data into a Plot\n",
    "sns.barplot(x = \"changes\", y = \"name\", data = mun_minmax, palette = \"GnBu\")\n",
    "plt.title(\"The Biggest Changes in Population 2017-2027, Municipality\")\n",
    "plt.xlabel(\"Change in %\")\n",
    "plt.xticks(rotation = 30)\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "# Save and Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/TopFlopMunicipalityPred.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/TopFlopMunicipalityPred.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Here you can see the fastest growing/ shrinking municipalities.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> Let's see what if there are any patterns in the age-structure of the inner-german migration.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Choose Data to Cluster\n",
    "cluster_me = data_dis[[\"fam_balance_2017\",\"edu_balance_2017\",\"sec_balance_2017\",\"ger_balance_2017\"]]\n",
    "\n",
    "# Set Up Collector for Results\n",
    "results = []\n",
    "# Cycle through different number of clusters\n",
    "for idx in range(2,12):\n",
    "\n",
    "    # Cluster Data by applyinge KMeans\n",
    "    kmeans = KMeans(n_clusters = idx)\n",
    "    kmeans.fit(cluster_me)\n",
    "    y_kmeans = kmeans.predict(cluster_me)\n",
    "    \n",
    "    # Sort Data\n",
    "    counter = 0\n",
    "    micro_vault = []\n",
    "    while counter < idx:\n",
    "        result = pd.DataFrame(cluster_me[y_kmeans == counter])\n",
    "        micro_vault.append(result)\n",
    "        counter +=1\n",
    "    \n",
    "    # Calculate Silouette Score, and save result in Collector\n",
    "    results.append(silhouette_score(X = cluster_me, labels = y_kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-Up Multi-Plot\n",
    "f, (leftplot, rightplot) = plt.subplots(1, 2)\n",
    "\n",
    "# Plot of Silhouette Score\n",
    "leftplot.set_xlabel(\"Number of Clusters\")\n",
    "leftplot.set_ylabel(\"Silhouette Score\")\n",
    "leftplot.set_title(\"Comparing Silhouette Score\")\n",
    "leftplot.set_xticks(range(0,10))\n",
    "leftplot.set_xticklabels(range(2,12))\n",
    "leftplot.plot(results);\n",
    "\n",
    "# Plot of Silhouette Score Gains\n",
    "rightplot.set_title(\"Gains by additional Cluster\")\n",
    "rightplot.set_xlabel(\"Number of Clusters\")\n",
    "rightplot.set_xticks(range(0,10))\n",
    "rightplot.set_xticklabels(range(3,11))\n",
    "rightplot.plot(np.diff(results));\n",
    "\n",
    "# Handle Results\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./images/ScoringClusters.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/ScoringClusters.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>As it can be seen here, the gains collapse after 4 clusters. Therefore I choose to cluster the Distircts into 4 clusters.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Data\n",
    "kmeans = KMeans(n_clusters = n)\n",
    "kmeans.fit(cluster_me)\n",
    "y_kmeans = pd.Series(kmeans.predict(cluster_me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-Up Multi-Plot\n",
    "f, (leftplot, rightplot) = plt.subplots(1, 2)\n",
    "\n",
    "leftplot.set_title(\"Districts Migration Age Profiles\")\n",
    "counter = 0\n",
    "while counter < n:\n",
    "    leftplot.plot(cluster_me[y_kmeans==counter].mean())\n",
    "    counter += 1\n",
    "leftplot.set_xticks(range(0,4))\n",
    "leftplot.set_xticklabels([\"Family\",\"Education\",\"Second Half\",\"Old Age\"])\n",
    "leftplot.set_xlabel(\"Migration Age Group\")\n",
    "\n",
    "rightplot.set_title(\"Number of Districts with Profile\")\n",
    "for idx in range(0,n):\n",
    "    rightplot.bar(x      = idx,\n",
    "                  height = (y_kmeans==idx).sum())\n",
    "rightplot.set_xticks(range(0,4))\n",
    "rightplot.set_xticklabels([\"Neutral\",\"Magnet\",\"Repulsing\",\"Attracting\"])\n",
    "\n",
    "plt.savefig(\"./images/Clusters.png\")\n",
    "plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./images/Clusters.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>It seems the 4 Clusters are mostly differentiable by thier attraction to the Educational Migration Group. I divided the districts therefore into those four: Repulsing, Neutral, Attracting and Magnets.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Data for Demonstrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Data\n",
    "for_export                 = predictionS(10,bc_dis_pop,mm_dis_pop)\n",
    "\n",
    "data_export                = pd.DataFrame([])\n",
    "data_export[\"name\"]        = data_dis.name\n",
    "data_export[\"code\"]        = data_dis.gkz\n",
    "data_export[\"pred_2018\"]   = for_export.loc[:,2018].astype(int)\n",
    "data_export[\"pred_2022\"]   = for_export.loc[:,2022].astype(int)\n",
    "data_export[\"pred_2026\"]   = for_export.loc[:,2026].astype(int)\n",
    "data_export[\"mig_profile\"] = y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Data\n",
    "data_export.to_csv(path_or_buf = \"data_demo.csv\",\n",
    "                   index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Conclusion'></a>\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Some of the results are conclusive, while others seem outright unrealistic. In the end, more data is needed, data that truely holds the possibility to determine the attractiveness of a municipality or district.<br>\n",
    "In general the approach is feasable, it needs to be altered. Right now it is a purely \"Data-Science\" approach: Population is an infinite resource. In a future iteration the total population needs to be predicted, followed by a division into mobile, and immobile inhabitants. Then, the mobile ones are distributed among the districts/ municiplaities, based on a predicted attractiveness-factor.<br>\n",
    "In the end, the lines between Data-Science and Simulation need to be blurred.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='FutureWorks'></a>\n",
    "## Future Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implement Geospatial Visualization of Municipality Level<br>\n",
    "- Implement Categorical Feature: Type of District/ Municipality<br>\n",
    "- Mature Missing Value Handling<br>\n",
    "- Counter the influence of the Census 2011<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
